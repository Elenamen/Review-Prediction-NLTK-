# Review-Prediction-NLTK-

Tokenization--> breaking down the document into different words

Stemming --> NLP technique that reduces words to their root/base form (ie. retrieval,retrieved,retrieves >> retrieve)
              Part of the NLP pipeline process
              Different algorithms for stemming, ie.Porter stemmer,Snowball,Lancaster
              Input of the stemmer: tokenized words

Lemmatization --> Process of reducing a word to its base form, but unlike stemming, it takes into account the context of the word, and it produces a valid word, unlike stemming which may produce a non-word as the root form.
